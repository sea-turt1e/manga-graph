#!/usr/bin/env python
"""Import manga_details.json data into Neo4j.

This script reads the manga_details.json file generated by 
fetch_manga_details_from_mal_api.py and updates existing Work nodes in Neo4j
with detailed information including:
- Updated properties (synopsis, background, pictures, etc.)
- PUBLISHED_IN relationships (Work -> Magazine)
- Additional CREATED_BY relationships if missing

This is meant to be run AFTER the initial import with import_mal_api_to_neo4j.py.

Usage:
    # Import manga details with all relationships
    python scripts/data_import/import_manga_details_to_neo4j.py
    
    # Specify input file
    python scripts/data_import/import_manga_details_to_neo4j.py --input data/mal_api/manga_details.json
    
    # Dry run to see what would be imported
    python scripts/data_import/import_manga_details_to_neo4j.py --dry-run
    
    # Import only the first N items
    python scripts/data_import/import_manga_details_to_neo4j.py --limit 100
"""

from __future__ import annotations

import argparse
import json
import os
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterator, List, Optional, Set, Tuple

from neo4j import Driver, GraphDatabase
from tqdm.auto import tqdm

# Ensure the project root is on sys.path
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from config import env  # noqa: F401


@dataclass
class ImportConfig:
    input_file: Path
    uri: str
    user: str
    password: str
    batch_size: int = 500
    limit: Optional[int] = None
    dry_run: bool = False
    update_properties: bool = True
    create_published_in: bool = True
    create_created_by: bool = True


def parse_args(argv: Optional[List[str]] = None) -> ImportConfig:
    parser = argparse.ArgumentParser(
        description="Import manga_details.json into Neo4j",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "--input",
        type=Path,
        default=Path("data/mal_api/manga_details.json"),
        help="Path to manga_details.json file",
    )
    parser.add_argument(
        "--uri",
        type=str,
        default=os.getenv("NEO4J_URI", "bolt://localhost:7687"),
        help="Neo4j bolt URI",
    )
    parser.add_argument(
        "--user",
        type=str,
        default=os.getenv("NEO4J_USER", "neo4j"),
        help="Neo4j user",
    )
    parser.add_argument(
        "--password",
        type=str,
        default=os.getenv("NEO4J_PASSWORD", "password"),
        help="Neo4j password",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=500,
        help="Number of items per transaction",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="Import only the first N items",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview import without writing to Neo4j",
    )
    parser.add_argument(
        "--no-update-properties",
        action="store_true",
        help="Skip updating Work node properties",
    )
    parser.add_argument(
        "--no-published-in",
        action="store_true",
        help="Skip creating PUBLISHED_IN relationships",
    )
    parser.add_argument(
        "--no-created-by",
        action="store_true",
        help="Skip creating CREATED_BY relationships",
    )
    
    args = parser.parse_args(argv)
    
    return ImportConfig(
        input_file=args.input.expanduser().resolve(),
        uri=args.uri,
        user=args.user,
        password=args.password,
        batch_size=args.batch_size,
        limit=args.limit,
        dry_run=args.dry_run,
        update_properties=not args.no_update_properties,
        create_published_in=not args.no_published_in,
        create_created_by=not args.no_created_by,
    )


def chunked(items: List[Any], size: int) -> Iterator[List[Any]]:
    """Yield chunks of the given size from the list."""
    for i in range(0, len(items), size):
        yield items[i:i + size]


def load_manga_details(input_file: Path) -> List[Dict[str, Any]]:
    """Load manga details from JSON file."""
    if not input_file.exists():
        print(f"Error: File not found: {input_file}")
        return []
    
    print(f"Loading {input_file}...")
    with open(input_file, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    # Handle format: {"manga": [...], "metadata": {...}}
    if isinstance(data, dict):
        manga_list = data.get("manga", [])
    else:
        manga_list = data
    
    print(f"Loaded {len(manga_list)} manga entries")
    return manga_list


def extract_serialization_data(manga: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Extract serialization (magazine) data from manga details."""
    serialization = manga.get("serialization", [])
    if not serialization:
        return []
    
    magazines = []
    for serial in serialization:
        node = serial.get("node", serial)
        if node and node.get("name"):
            magazines.append({
                "id": node.get("id"),
                "name": node.get("name"),
            })
    
    return magazines


def extract_author_data(manga: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Extract author data from manga details."""
    authors = manga.get("authors", [])
    if not authors:
        return []
    
    author_list = []
    for author_entry in authors:
        node = author_entry.get("node", author_entry)
        role = author_entry.get("role", "")
        
        if node:
            first_name = node.get("first_name", "")
            last_name = node.get("last_name", "")
            author_id = node.get("id")
            
            # Build full name
            if first_name and last_name:
                full_name = f"{first_name} {last_name}"
            elif last_name:
                full_name = last_name
            elif first_name:
                full_name = first_name
            else:
                continue
            
            author_list.append({
                "id": author_id,
                "name": full_name.strip(),
                "first_name": first_name,
                "last_name": last_name,
                "role": role,
            })
    
    return author_list


class MangaDetailsImporter:
    """Importer for manga details JSON data into Neo4j."""
    
    def __init__(self, driver: Driver, batch_size: int = 500) -> None:
        self.driver = driver
        self.batch_size = batch_size
        self._ensure_indexes()
    
    def _ensure_indexes(self) -> None:
        """Ensure necessary indexes exist."""
        with self.driver.session() as session:
            # Index for Work nodes
            session.run("""
                CREATE INDEX IF NOT EXISTS FOR (w:Work) ON (w.mal_id)
            """)
            # Index for Magazine nodes
            session.run("""
                CREATE INDEX IF NOT EXISTS FOR (m:Magazine) ON (m.name)
            """)
            # Index for Author nodes  
            session.run("""
                CREATE INDEX IF NOT EXISTS FOR (a:Author) ON (a.name)
            """)
    
    def update_work_properties(
        self, manga_list: List[Dict[str, Any]], dry_run: bool = False
    ) -> int:
        """Update Work node properties with detailed data."""
        if dry_run:
            print(f"[DRY RUN] Would update properties for {len(manga_list)} works")
            return len(manga_list)
        
        updated = 0
        for chunk in tqdm(
            list(chunked(manga_list, self.batch_size)),
            desc="Updating Work properties",
        ):
            params_list = []
            for manga in chunk:
                mal_id = manga.get("id")
                if not mal_id:
                    continue
                
                # Properties to update
                props = {
                    "mal_id": mal_id,
                    "synopsis": manga.get("synopsis"),
                    "background": manga.get("background"),
                    "num_volumes": manga.get("num_volumes"),
                    "num_chapters": manga.get("num_chapters"),
                }
                
                # Store pictures as JSON string
                pictures = manga.get("pictures", [])
                if pictures:
                    props["pictures"] = json.dumps(pictures)
                
                # Remove None values
                props = {k: v for k, v in props.items() if v is not None}
                params_list.append(props)
            
            if params_list:
                with self.driver.session() as session:
                    result = session.run("""
                        UNWIND $params AS p
                        MATCH (w:Work {mal_id: p.mal_id})
                        SET w += p
                        RETURN count(w) as updated
                    """, params=params_list)
                    record = result.single()
                    if record:
                        updated += record["updated"]
        
        return updated
    
    def create_published_in_relationships(
        self, manga_list: List[Dict[str, Any]], dry_run: bool = False
    ) -> Tuple[int, int]:
        """Create Magazine nodes and PUBLISHED_IN relationships."""
        # Collect all magazine data
        work_magazine_pairs: List[Tuple[int, str]] = []
        all_magazines: Dict[str, Dict[str, Any]] = {}
        
        for manga in manga_list:
            mal_id = manga.get("id")
            if not mal_id:
                continue
            
            magazines = extract_serialization_data(manga)
            for mag in magazines:
                mag_name = mag.get("name")
                if mag_name:
                    all_magazines[mag_name] = mag
                    work_magazine_pairs.append((mal_id, mag_name))
        
        if dry_run:
            print(f"[DRY RUN] Would create {len(all_magazines)} Magazine nodes")
            print(f"[DRY RUN] Would create {len(work_magazine_pairs)} PUBLISHED_IN relationships")
            return len(all_magazines), len(work_magazine_pairs)
        
        # Create Magazine nodes
        magazines_created = 0
        magazine_list = list(all_magazines.values())
        if magazine_list:
            with self.driver.session() as session:
                result = session.run("""
                    UNWIND $magazines AS m
                    MERGE (mag:Magazine {name: m.name})
                    ON CREATE SET mag.mal_id = m.id
                    RETURN count(mag) as created
                """, magazines=magazine_list)
                record = result.single()
                if record:
                    magazines_created = record["created"]
        
        # Create PUBLISHED_IN relationships
        relationships_created = 0
        for chunk in tqdm(
            list(chunked(work_magazine_pairs, self.batch_size)),
            desc="Creating PUBLISHED_IN relationships",
        ):
            pairs = [{"mal_id": pair[0], "magazine_name": pair[1]} for pair in chunk]
            
            with self.driver.session() as session:
                result = session.run("""
                    UNWIND $pairs AS p
                    MATCH (w:Work {mal_id: p.mal_id})
                    MATCH (m:Magazine {name: p.magazine_name})
                    MERGE (w)-[r:PUBLISHED_IN]->(m)
                    RETURN count(r) as created
                """, pairs=pairs)
                record = result.single()
                if record:
                    relationships_created += record["created"]
        
        return magazines_created, relationships_created
    
    def create_created_by_relationships(
        self, manga_list: List[Dict[str, Any]], dry_run: bool = False
    ) -> Tuple[int, int]:
        """Create Author nodes and CREATED_BY relationships."""
        # Collect all author data
        work_author_pairs: List[Dict[str, Any]] = []
        all_authors: Dict[str, Dict[str, Any]] = {}
        
        for manga in manga_list:
            mal_id = manga.get("id")
            if not mal_id:
                continue
            
            authors = extract_author_data(manga)
            for author in authors:
                author_name = author.get("name")
                if author_name:
                    all_authors[author_name] = author
                    work_author_pairs.append({
                        "mal_id": mal_id,
                        "author_name": author_name,
                        "role": author.get("role", ""),
                    })
        
        if dry_run:
            print(f"[DRY RUN] Would create {len(all_authors)} Author nodes")
            print(f"[DRY RUN] Would create {len(work_author_pairs)} CREATED_BY relationships")
            return len(all_authors), len(work_author_pairs)
        
        # Create Author nodes
        authors_created = 0
        author_list = list(all_authors.values())
        if author_list:
            with self.driver.session() as session:
                result = session.run("""
                    UNWIND $authors AS a
                    MERGE (author:Author {name: a.name})
                    ON CREATE SET 
                        author.mal_id = a.id,
                        author.first_name = a.first_name,
                        author.last_name = a.last_name
                    RETURN count(author) as created
                """, authors=author_list)
                record = result.single()
                if record:
                    authors_created = record["created"]
        
        # Create CREATED_BY relationships
        relationships_created = 0
        for chunk in tqdm(
            list(chunked(work_author_pairs, self.batch_size)),
            desc="Creating CREATED_BY relationships",
        ):
            with self.driver.session() as session:
                result = session.run("""
                    UNWIND $pairs AS p
                    MATCH (w:Work {mal_id: p.mal_id})
                    MATCH (a:Author {name: p.author_name})
                    MERGE (w)-[r:CREATED_BY]->(a)
                    ON CREATE SET r.role = p.role
                    RETURN count(r) as created
                """, pairs=chunk)
                record = result.single()
                if record:
                    relationships_created += record["created"]
        
        return authors_created, relationships_created


def main(argv: Optional[List[str]] = None) -> int:
    config = parse_args(argv)
    
    # Load data
    manga_list = load_manga_details(config.input_file)
    if not manga_list:
        return 1
    
    # Apply limit if specified
    if config.limit:
        manga_list = manga_list[:config.limit]
        print(f"Limited to {len(manga_list)} items")
    
    if config.dry_run:
        print("\n=== DRY RUN MODE ===\n")
    
    # Connect to Neo4j
    print(f"Connecting to Neo4j at {config.uri}...")
    driver = GraphDatabase.driver(config.uri, auth=(config.user, config.password))
    
    try:
        driver.verify_connectivity()
        print("Connected to Neo4j")
    except Exception as e:
        print(f"Failed to connect to Neo4j: {e}")
        return 1
    
    importer = MangaDetailsImporter(driver, config.batch_size)
    
    # Import statistics
    stats = {
        "works_updated": 0,
        "magazines_created": 0,
        "published_in_created": 0,
        "authors_created": 0,
        "created_by_created": 0,
    }
    
    try:
        # Update Work properties
        if config.update_properties:
            print("\n--- Updating Work properties ---")
            stats["works_updated"] = importer.update_work_properties(
                manga_list, config.dry_run
            )
        
        # Create PUBLISHED_IN relationships
        if config.create_published_in:
            print("\n--- Creating PUBLISHED_IN relationships ---")
            magazines, published_in = importer.create_published_in_relationships(
                manga_list, config.dry_run
            )
            stats["magazines_created"] = magazines
            stats["published_in_created"] = published_in
        
        # Create CREATED_BY relationships
        if config.create_created_by:
            print("\n--- Creating CREATED_BY relationships ---")
            authors, created_by = importer.create_created_by_relationships(
                manga_list, config.dry_run
            )
            stats["authors_created"] = authors
            stats["created_by_created"] = created_by
        
        # Print summary
        print("\n" + "=" * 50)
        print("IMPORT SUMMARY")
        print("=" * 50)
        print(f"Works updated:              {stats['works_updated']:,}")
        print(f"Magazines created:          {stats['magazines_created']:,}")
        print(f"PUBLISHED_IN relationships: {stats['published_in_created']:,}")
        print(f"Authors created:            {stats['authors_created']:,}")
        print(f"CREATED_BY relationships:   {stats['created_by_created']:,}")
        
        if config.dry_run:
            print("\n[DRY RUN] No changes were made to the database")
        
    finally:
        driver.close()
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
